<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>G-Retriever for Obsidian Vault - Documentation</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }

        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }

        header h1 {
            font-size: 3em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        }

        header p {
            font-size: 1.3em;
            opacity: 0.95;
        }

        nav {
            background: #f8f9fa;
            padding: 20px 40px;
            border-bottom: 3px solid #667eea;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        nav ul {
            list-style: none;
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
        }

        nav a {
            color: #667eea;
            text-decoration: none;
            font-weight: 600;
            transition: color 0.3s;
        }

        nav a:hover {
            color: #764ba2;
        }

        main {
            padding: 40px;
        }

        section {
            margin-bottom: 60px;
        }

        h2 {
            color: #667eea;
            font-size: 2.2em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #667eea;
        }

        h3 {
            color: #764ba2;
            font-size: 1.6em;
            margin: 30px 0 15px 0;
        }

        h4 {
            color: #555;
            font-size: 1.3em;
            margin: 20px 0 10px 0;
        }

        p {
            margin-bottom: 15px;
        }

        ul, ol {
            margin: 15px 0 15px 30px;
        }

        li {
            margin-bottom: 8px;
        }

        .info-box {
            background: #e8f4f8;
            border-left: 5px solid #667eea;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .warning-box {
            background: #fff3cd;
            border-left: 5px solid #ff9800;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .success-box {
            background: #d4edda;
            border-left: 5px solid #28a745;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        code {
            background: #f4f4f4;
            padding: 3px 8px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            color: #d63384;
        }

        pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            border-left: 5px solid #667eea;
        }

        pre code {
            background: none;
            color: inherit;
            padding: 0;
        }

        .module-card {
            background: linear-gradient(135deg, #667eea15 0%, #764ba215 100%);
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 25px;
            margin: 20px 0;
            transition: transform 0.3s, box-shadow 0.3s;
        }

        .module-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.2);
        }

        .module-card h4 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.4em;
        }

        .pipeline-step {
            display: flex;
            align-items: flex-start;
            gap: 20px;
            margin: 30px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
            border-left: 5px solid #667eea;
        }

        .step-number {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5em;
            font-weight: bold;
            flex-shrink: 0;
        }

        .step-content {
            flex: 1;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            text-align: left;
        }

        td {
            padding: 12px 15px;
            border-bottom: 1px solid #ddd;
        }

        tr:hover {
            background: #f5f5f5;
        }

        .architecture-diagram {
            background: white;
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 30px;
            margin: 30px 0;
            text-align: center;
        }

        .component {
            display: inline-block;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px 30px;
            margin: 10px;
            border-radius: 8px;
            font-weight: 600;
        }

        .arrow {
            font-size: 2em;
            color: #667eea;
            margin: 0 10px;
        }

        footer {
            background: #2d2d2d;
            color: white;
            text-align: center;
            padding: 30px;
            margin-top: 40px;
        }

        .btn {
            display: inline-block;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 12px 30px;
            border-radius: 25px;
            text-decoration: none;
            font-weight: 600;
            transition: transform 0.3s, box-shadow 0.3s;
            margin: 10px 5px;
        }

        .btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.4);
        }

        .comparison-table {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 30px 0;
        }

        .comparison-card {
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 25px;
            background: white;
        }

        .comparison-card h4 {
            color: #667eea;
            margin-bottom: 15px;
        }

        .comparison-card ul {
            list-style: none;
            padding-left: 0;
        }

        .comparison-card li {
            padding: 8px 0;
            padding-left: 25px;
            position: relative;
        }

        .comparison-card li:before {
            content: "‚úì";
            position: absolute;
            left: 0;
            color: #28a745;
            font-weight: bold;
        }

        @media (max-width: 768px) {
            .comparison-table {
                grid-template-columns: 1fr;
            }

            header h1 {
                font-size: 2em;
            }

            nav ul {
                flex-direction: column;
                gap: 10px;
            }

            .pipeline-step {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üß† G-Retriever for Obsidian</h1>
            <p>Transform your Obsidian Vault into an intelligent, searchable knowledge graph</p>
        </header>

        <nav>
            <ul>
                <li><a href="#overview">Overview</a></li>
                <li><a href="#architecture">Architecture</a></li>
                <li><a href="#installation">Installation</a></li>
                <li><a href="#modules">Modules</a></li>
                <li><a href="#workflow">Workflow</a></li>
                <li><a href="#training">Training</a></li>
                <li><a href="#usage">Usage</a></li>
                <li><a href="#comparison">Comparison</a></li>
            </ul>
        </nav>

        <main>
            <section id="overview">
                <h2>üìñ Overview</h2>
                <p>This system transforms your Obsidian Vault into a searchable knowledge graph using Graph Neural Networks and Large Language Models. It combines modern RAG (Retrieval-Augmented Generation) techniques with G-Retriever to provide precise answers based on your personal notes.</p>

                <div class="info-box">
                    <h4>üéØ What does the system do?</h4>
                    <ul>
                        <li><strong>Graph Conversion:</strong> Converts Markdown notes into a NetworkX graph</li>
                        <li><strong>QA Generation:</strong> Automatically creates question-answer pairs using Ollama</li>
                        <li><strong>Smart Retrieval:</strong> Finds relevant notes using embeddings and graph algorithms</li>
                        <li><strong>Contextual Answers:</strong> Uses your local LLM for precise answers</li>
                        <li><strong>Optional: GNN Training:</strong> Trains a specialized neural network on your data</li>
                    </ul>
                </div>

                <div class="architecture-diagram">
                    <h3>System Architecture</h3>
                    <div>
                        <div class="component">Obsidian Vault</div>
                        <span class="arrow">‚Üí</span>
                        <div class="component">Graph Builder</div>
                        <span class="arrow">‚Üí</span>
                        <div class="component">Training Data</div>
                        <span class="arrow">‚Üí</span>
                        <div class="component">PyG Dataset</div>
                        <span class="arrow">‚Üí</span>
                        <div class="component">GNN Training</div>
                        <span class="arrow">‚Üí</span>
                        <div class="component">Chat Interface</div>
                    </div>
                </div>
            </section>

            <section id="architecture">
                <h2>üèóÔ∏è Technical Architecture</h2>

                <h3>Two variants available:</h3>

                <div class="comparison-table">
                    <div class="comparison-card">
                        <h4>G-Retriever Light (Untrained)</h4>
                        <ul>
                            <li>Ready to use immediately</li>
                            <li>No GPU required</li>
                            <li>Fast responses</li>
                            <li>Embedding-based retrieval</li>
                            <li>PCST subgraph construction</li>
                            <li>Ollama for answer generation</li>
                        </ul>
                        <div class="success-box">
                            <strong>Recommendation:</strong> Start with this! It works very well without training.
                        </div>
                    </div>

                    <div class="comparison-card">
                        <h4>G-Retriever Full (Trained)</h4>
                        <ul>
                            <li>Requires training (1-3h)</li>
                            <li>GPU recommended</li>
                            <li>Specialized for your data</li>
                            <li>GNN-based retrieval</li>
                            <li>Graph Attention Networks</li>
                            <li>5-10% better results</li>
                        </ul>
                        <div class="warning-box">
                            <strong>Note:</strong> Only necessary for enthusiasts or large vaults (>5000 notes).
                        </div>
                    </div>
                </div>

                <h3>Core components:</h3>

                <div class="module-card">
                    <h4>1. Graph Neural Network (GAT)</h4>
                    <p>Uses Graph Attention Networks to learn relationships between notes. With 3 layers and 4 attention heads, the model can recognize complex connection patterns.</p>
                </div>

                <div class="module-card">
                    <h4>2. Sentence Transformers</h4>
                    < p>Creates semantic embeddings for all notes. The model <code>all-MiniLM-L6-v2</code> is fast and efficient with 384-dimensional vectors.</p>
                </div>

                <div class="module-card">
                    <h4>3. PCST Algorithm</h4>
                    <p>Prize-Collecting Steiner Tree finds the optimally connected subgraph from relevant nodes ‚Äì essential for coherent answers.</p>
                </div>

                <div class="module-card">
                    <h4>4. Ollama LLM</h4>
                    <p>Your local Llama3 model generates the final answers based on the retrieved context. Complete privacy, no cloud!</p>
                </div>
            </section>

            <section id="installation">
                <h2>‚öôÔ∏è Installation</h2>

                <h3>Requirements:</h3>
                <ul>
                    <li>Python 3.9 or higher</li>
                    <li>CUDA (optional, for GPU acceleration)</li>
                    <li>Ollama installed with <code>llama3:8b</code> model</li>
                    <li>Approx. 10 GB free storage space</li>
                </ul>

                <h3>Step 1: Virtual Environment</h3>
                <pre><code>python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate  # Windows</code></pre>

                <h3>Step 2: Install PyTorch</h3>
                <pre><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</code></pre>

                <h3>Step 3: PyTorch Geometric</h3>
                <pre><code>pip install torch-geometric
pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html</code></pre>

                <h3>Step 4: Additional Dependencies</h3>
                <pre><code>pip install sentence-transformers networkx pcst-fast requests tqdm numpy pandas</code></pre>

                <h3>Step 5: Set up Ollama</h3>
                <pre><code># Check if Ollama is running
curl http://localhost:11434/api/version

# Pull Llama3 model
ollama pull llama3:8b</code></pre>

                <div class="success-box">
                    <strong>‚úì Installation complete!</strong> You are ready to get started.
                </div>

            </section>

            <section id="modules">
                <h2>üì¶ Modules</h2>

                <div class="module-card">
                    <h4>1. obsidian_to_graph.py</h4>
                    <p><strong>Function:</strong> Converts Obsidian Vault into a NetworkX graph</p>
                    <p><strong>Input:</strong> Path to the vault</p>
                    <p><strong>Output:</strong> <code>graph.gpickle</code>, <code>graph.json</code>, <code>stats.json</code></p>
                    <p><strong>Features:</strong></p>
                    <ul>
                        <li>Parses Markdown files</li>
                        <li>Extracts Wiki-links [[link]] and Markdown links</li>
                        <li>Automatically removes images</li>
                        <li>Extracts #tags</li>
                        <li>Creates a directed graph with edges for links</li>
                    </ul>
                </div>

                <div class="module-card">
                    <h4>2. generate_training_data.py</h4>
                    <p><strong>Function:</strong> Generates QA pairs using Ollama</p>
                    <p><strong>Input:</strong> <code>graph.gpickle</code></p>
                    <p><strong>Output:</strong> <code>train.json</code>, <code>val.json</code>, <code>qa_pairs.json</code></p>
                    <p><strong>Question types:</strong></p>
                    <ul>
                        <li><strong>Factual:</strong> Precise factual questions</li>
                        <li><strong>Connection:</strong> Questions about relationships</li>
                        <li><strong>Summary:</strong> Summary questions</li>
                        <li><strong>Multi-Node:</strong> Questions spanning multiple connected notes</li>
                    </ul>
                    <p><strong>Performance:</strong> ~500 QA pairs in 1-2 hours</p>
                </div>

                <div class="module-card">
                    <h4>3. pyg_dataset.py</h4>
                    <p><strong>Function:</strong> Creates PyTorch Geometric datasets</p>
                    <p><strong>Input:</strong> Graph + QA JSONs</p>
                    <p><strong>Output:</strong> <code>train_data.pt</code>, <code>val_data.pt</code></p>
                    <p><strong>Features:</strong></p>
                    <ul>
                        <li>Node embeddings with Sentence Transformers</li>
                        <li>Question embeddings</li>
                        <li>Edge index for GNN</li>
                        <li>80/20 train/val split</li>
                    </ul>
                </div>

                <div class="module-card">
                    <h4>4. gretriever_inference.py</h4>
                    <p><strong>Function:</strong> Chat interface (untrained)</p>
                    <p><strong>Pipeline:</strong></p>
                    <ol>
                        <li><strong>Retrieval:</strong> k-NN with cosine similarity</li>
                        <li><strong>Subgraph Construction:</strong> PCST for optimal subgraph</li>
                        <li><strong>Answer Generation:</strong> Ollama with context</li>
                    </ol>
                    <p><strong>Advantage:</strong> Ready to use immediately, no training needed!</p>
                </div>

                <div class="module-card">
                    <h4>5. train_gretriever.py</h4>
                    <p><strong>Function:</strong> Trains GNN on QA pairs</p>
                    <p><strong>Model:</strong> GAT (Graph Attention Network)</p>
                    <p><strong>Loss:</strong> Binary Cross Entropy (relevant vs. irrelevant nodes)</p>
                    <p><strong>Optimizer:</strong> Adam with learning rate 0.001</p>
                    <p><strong>Training:</strong> 20 epochs, ~1-3 hours</p>
                </div>

                <div class="module-card">
                    <h4>6. gretriever_inference_trained.py</h4>
                    <p><strong>Function:</strong> Chat interface with trained GNN</p>
                    <p><strong>Difference:</strong> Uses trained model for retrieval instead of embeddings</p>
                    <p><strong>Performance:</strong> 5-10% better relevance for large vaults</p>
                </div>

                <div class="module-card">
                    <h4>7. pipeline.py</h4>
                    <p><strong>Function:</strong> Runs the complete pipeline automatically</p>
                    <p><strong>Options:</strong> Skip individual steps with <code>--skip</code></p>
                    <p><strong>Perfect for:</strong> Initial setup or restart</p>
                </div>
            </section>

            <section id="workflow">
                <h2>üîÑ Workflow</h2>

                <h3>Quick Start (Untrained Variant):</h3>

                <div class="pipeline-step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h4>Create graph</h4>
                        <pre><code>python obsidian_to_graph.py</code></pre>
                        <p>Converts your notes into a graph. Takes: ~1-5 minutes for 1100 notes.</p>
                    </div>
                </div>

                <div class="pipeline-step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h4>Generate training data</h4>
                        <pre><code>python generate_training_data.py</code></pre>
                        <p>Creates 500 QA pairs using Ollama. Takes: 1-2 hours.</p>
                        <div class="warning-box">
                            <strong>Tip:</strong> Start with 200 QA pairs for testing (<code>num_samples=200</code>), then expand to 500-1000.
                        </div>
                    </div>
                </div>

                <div class="pipeline-step">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h4>Start chat</h4>
                        <pre><code>python gretriever_inference.py</code></pre>
                        <p>Interactive chat interface opens. Ask questions about your notes!</p>
                    </div>
                </div>

                <h3>Advanced (Trained Variant):</h3>

                <div class="pipeline-step">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h4>Create PyG dataset</h4>
                        <pre><code>python pyg_dataset.py</code></pre>
                        <p>Converts data into PyTorch Geometric format. Takes: 5-10 minutes.</p>
                    </div>
                </div>

                <div class="pipeline-step">
                    <div class="step-number">5</div>
                    <div class="step-content">
                        <h4>GNN Training</h4>
                        <pre><code>python train_gretriever.py</code></pre>
                        <p>Trains the Graph Neural Network. Takes: 1-3 hours depending on hardware.</p>
                        <div class="info-box">
                            <strong>GPU Tip:</strong> With GPU 3-5x faster. CPU works too!
                        </div>
                    </div>
                </div>

                <div class="pipeline-step">
                    <div class="step-number">6</div>
                    <div class="step-content">
                        <h4>Chat with trained model</h4>
                        <pre><code>python gretriever_inference_trained.py</code></pre>
                        <p>Uses the trained model for better retrieval.</p>
                    </div>
                </div>
            </section>

            <section id="training">
                <h2>üéì Training Details</h2>

                <h3>How many training data do you need?</h3>

                <table>
                    <thead>
                        <tr>
                            <th>Vault Size</th>
                            <th>Recommended QA Pairs</th>
                            <th>Duration</th>
                            <th>Purpose</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>< 500 notes</td>
                            <td>200-300</td>
                            <td>30-60 min</td>
                            <td>Quick Test</td>
                        </tr>
                        <tr>
                            <td>500-1500 notes</td>
                            <td>500-800</td>
                            <td>1-2 h</td>
                            <td>Standard (recommended)</td>
                        </tr>
                        <tr>
                            <td>1500-3000 notes</td>
                            <td>1000-1500</td>
                            <td>3-4 h</td>
                            <td>Good coverage</td>
                        </tr>
                        <tr>
                            <td>> 3000 notes</td>
                            <td>2000+</td>
                            <td>6+ h</td>
                            <td>Very good</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Training Hyperparameters:</h3>

                <div class="module-card">
                    <h4>Model Architecture</h4>
                    <ul>
                        <li><strong>Node Embed Dim:</strong> 384 (from Sentence Transformer)</li>
                        <li><strong>Hidden Dim:</strong> 256</li>
                        <li><strong>Num Layers:</strong> 3</li>
                        <li><strong>Attention Heads:</strong> 4</li>
                        <li><strong>Total Parameters:</strong> ~2.5M</li>
                    </ul>
                </div>

                <div class="module-card">
                    <h4>Training Setup</h4>
                    <ul>
                        <li><strong>Optimizer:</strong> Adam</li>
                        <li><strong>Learning Rate:</strong> 0.001</li>
                        <li><strong>Loss Function:</strong> BCE with Logits</li>
                        <li><strong>Epochs:</strong> 20 (default)</li>
                        <li><strong>Batch Size:</strong> 1 (full graph per sample)</li>
                    </ul>
                </div>

                <div class="info-box">
                    <h4>üí° Training Tips:</h4>
                    <ul>
                        <li>Start with fewer epochs (10) for testing</li>
                        <li>Monitor validation loss ‚Äì stop early if overfitting</li>
                        <li>Best model is automatically saved</li>
                        <li>Training history is exported as JSON</li>
                    </ul>
                </div>
            </section>

            <section id="usage">
                <h2>üöÄ Usage</h2>

                <h3>Example Chat Session:</h3>

                <pre><code>$ python gretriever_inference.py

============================================================
G-Retriever Chat Interface for Obsidian Vault
Type 'quit' or 'exit' to end
============================================================

Your question: What are the most important concepts in my ML notes?
Query: What are the most important concepts in my ML notes?
Retrieving relevant nodes...
Constructing subgraph...
Generating answer...
Answer: Based on your notes, the most important Machine Learning
concepts are: Neural Networks with Backpropagation, Gradient Descent for
optimization, various Loss Functions (MSE, Cross-Entropy), and
regularization via L1/L2. You also have detailed notes on
Convolutional Neural Networks and their application in Computer Vision.
Used notes: Neural Networks, Backpropagation, Gradient Descent,
Loss Functions, Regularization</code></pre>

                <h3>Example Queries:</h3>

                <div class="module-card">
                    <h4>üîç Factual Questions</h4>
                    <ul>
                        <li>"What is the difference between L1 and L2 regularization?"</li>
                        <li>"Which Python libraries do I use for Data Science?"</li>
                        <li>"What does my note about Transformers say?"</li>
                    </ul>
                </div>

                <div class="module-card">
                    <h4>üîó Relationship Questions</h4>
                    <ul>
                        <li>"How are my notes on GraphQL and REST APIs connected?"</li>
                        <li>"Which projects use React?"</li>
                        <li>"What are the connections between my psychology notes?"</li>
                    </ul>
                </div>

                <div class="module-card">
                    <h4>üìä Summaries</h4>
                    <ul>
                        <li>"Summarize my notes on Quantum Computing"</li>
                        <li>"What have I learned about productivity?"</li>
                        <li>"Overview of my travel notes to Japan"</li>
                    </ul>
                </div>

                <h3>Code Adjustments:</h3>

                <h4>Adjust paths in the modules:</h4>

                <pre><code># In obsidian_to_graph.py
vault_path = "/path/to/your/vault"
output_path = "./graph_output"
In generate_training_data.py
graph_path = "./graph_output/graph.gpickle"
output_path = "./training_data"
num_samples = 500  # Number of QA pairs
In gretriever_inference.py
graph_path = "./graph_output/graph.gpickle"
ollama_model = "llama3:8b"</code></pre>
            </section>

            <section id="comparison">
                <h2>‚öñÔ∏è Untrained vs. Trained</h2>

                <h3>Performance Comparison:</h3>

                <table>
                    <thead>
                        <tr>
                            <th>Aspect</th>
                            <th>Untrained (Light)</th>
                            <th>Trained (Full)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Setup Time</strong></td>
                            <td>1-2 hours</td>
                            <td>3-5 hours</td>
                        </tr>
                        <tr>
                            <td><strong>GPU required?</strong></td>
                            <td>‚ùå No</td>
                            <td>‚ö†Ô∏è Recommended</td>
                        </tr>
                        <tr>
                            <td><strong>Retrieval Quality</strong></td>
                            <td>85-90%</td>
                            <td>90-95%</td>
                        </tr>
                        <tr>
                            <td><strong>Response Speed</strong></td>
                            <td>2-5 seconds</td>
                            <td>3-6 seconds</td>
                        </tr>
                        <tr>
                            <td><strong>Vault Size Recommendation</strong></td>
                            <td>< 2000 notes</td>
                            <td>> 2000 notes</td>
                        </tr>
                        <tr>
                            <td><strong>Maintenance</strong></td>
                            <td>None</td>
                            <td>Re-training for major changes</td>
                        </tr>
                        <tr>
                            <td><strong>Memory Requirement</strong></td>
                            <td>~2 GB RAM</td>
                            <td>~4 GB RAM + 2 GB VRAM</td>
                        </tr>
                    </tbody>
                </table>

                <div class="success-box">
                    <h4>‚ú® Recommendation:</h4>
                    <p><strong>Start with the untrained variant!</strong> It is quick to set up, works excellently, and you can start right away. Only train if:</p>
                    <ul>
                        <li>You have more than 2000-3000 notes</li>
                        <li>You need the absolute best retrieval quality</li>
                        <li>You enjoy experimenting</li>
                    </ul>
                    <p>The quality improvement from training is marginal (5-10%), but the effort is significantly higher.</p>
                </div>
            </section>

            <section id="troubleshooting">
                <h2>üîß Troubleshooting</h2>

                <div class="warning-box">
                    <h4>Problem: Ollama Connection Error</h4>
                    <p><strong>Solution:</strong></p>
                    <pre><code># Check if Ollama is running
curl http://localhost:11434/api/version
Start Ollama
ollama serve</code></pre>
                </div>
                <div class="warning-box">
                    <h4>Problem: CUDA Out of Memory</h4>
                    <p><strong>Solution:</strong></p>
                    <pre><code># In gretriever_inference.py or train_gretriever.py
device = "cpu"  # Instead of "cuda"</code></pre>
                </div>
                <div class="warning-box">
                    <h4>Problem: Too few QA pairs generated</h4>
                    <p><strong>Causes:</strong></p>
                    <ul>
                        <li>Many notes are too short (< 100 characters)</li>
                        <li>JSON parsing fails</li>
                        <li>Ollama timeouts</li>
                    </ul>
                    <p><strong>Solution:</strong> Increase <code>num_samples</code> by 20-30% more than desired.</p>
                </div>

                <div class="warning-box">
                    <h4>Problem: Import Errors</h4>
                    <p><strong>Solution:</strong></p>
                    <pre><code># Reinstall dependencies
pip install --force-reinstall torch-geometric
pip install pyg-lib torch-scatter torch-sparse</code></pre>
                </div>
                <div class="warning-box">
                    <h4>Problem: Training very slow</h4>
                    <p><strong>Optimizations:</strong></p>
                    <ul>
                        <li>Use GPU instead of CPU</li>
                        <li>Reduce Hidden Dim to 128</li>
                        <li>Reduce Num Layers to 2</li>
                        <li>Use fewer QA pairs for first test</li>
                    </ul>
                </div>
            </section>

            <section id="advanced">
                <h2>üéØ Advanced Configuration</h2>

                <h3>Change Embedding Models:</h3>

                <div class="module-card">
                    <pre><code># Better quality (slower)
embedding_model = "all-mpnet-base-v2"
Multilingual
embedding_model = "paraphrase-multilingual-MiniLM-L12-v2"
Specialized for code
embedding_model = "microsoft/codebert-base"</code></pre>
                </div>
                <h3>Tune GNN Architecture:</h3>

                <div class="module-card">
                    <pre><code># More capacity
hidden_dim = 512
num_layers = 5
num_heads = 8
Faster, less capacity
hidden_dim = 128
num_layers = 2
num_heads = 2</code></pre>
                </div>
                <h3>Retrieval Parameters:</h3>

                <div class="module-card">
                    <pre><code># In gretriever_inference.py
More context
k_retrieve = 30  # Instead of 20
Larger subgraph
max_subgraph_size = 20  # In construct_subgraph_pcst
More notes in LLM context
max_context_nodes = 15  # In generate_answer</code></pre>
                </div>
                <h3>Switch Ollama Model:</h3>

                <div class="module-card">
                    <pre><code># Larger model (better quality)
ollama_model = "llama3:70b"
Faster model
ollama_model = "phi3:mini"
Specialized
ollama_model = "codellama:13b"  # For code-heavy vaults</code></pre>
                </div>

                <div class="module-card">
    <h4>‚ö†Ô∏è PCST Behavior: Selection, not Expansion</h4>

    <p>
        The Prize-Collecting Steiner Tree (PCST) step does <strong>not</strong> expand the
        retrieved node set. It performs a global optimization and
        <strong>selects</strong> a structurally optimal subset of nodes.
    </p>

    <div class="warning-box">
        <strong>Key Point:</strong><br>
        A retrieved node is <em>never guaranteed</em> to appear in the final subgraph.
        Retrieval provides candidates ‚Äî PCST decides which ones are worth keeping.
    </div>

    <p>
        In the current implementation, PCST is called as:
    </p>

    <pre><code>vertices, _ = pcst_fast(
    edges,
    prizes,
    costs,
    root,
    1,
    1,
    'strong'
)</code></pre>

    <h4>How PCST makes decisions</h4>

    <p><strong>1. Node Prizes</strong></p>
    <pre><code>prizes[relevant_nodes] = similarities[relevant_nodes]</code></pre>
    <ul>
        <li>Only retrieved nodes receive a prize &gt; 0</li>
        <li>All other nodes start with prize = 0</li>
        <li>A retrieved node is <em>optional</em>, not mandatory</li>
    </ul>

    <p><strong>2. Edge Costs</strong></p>
    <pre><code>costs = np.ones(edges.shape[0])</code></pre>
    <ul>
        <li>Each edge has uniform cost = 1</li>
        <li>Long or weakly connected paths are expensive</li>
    </ul>

    <p><strong>3. Optimization Criterion</strong></p>
    <pre><code>keep node if:  prize(node) ‚â• sum(edge costs to connect it)</code></pre>

    <ul>
        <li>High similarity + short distance ‚Üí kept</li>
        <li>Medium similarity + many hops ‚Üí dropped</li>
        <li>Low similarity + strong connectivity ‚Üí often kept</li>
    </ul>

    <div class="info-box">
        <strong>Formal Property:</strong><br>
        <code>subgraph ‚äÜ retrieved_nodes ‚à™ connector_nodes</code><br>
        PCST never guarantees that all retrieved nodes survive.
    </div>

    <h4>Why the subgraph is usually smaller than retrieval</h4>
    <ul>
        <li>Retrieved nodes may be thematically scattered</li>
        <li>Connection costs can outweigh semantic relevance</li>
        <li>Highly connected hubs are often preferred</li>
    </ul>

    <p>
        This explains why, for example, well-connected authors or concepts
        may remain in the subgraph while isolated but semantically relevant
        notes are removed.
    </p>

    <h4>How to influence PCST behavior</h4>

    <p>
        You can actively steer how selective PCST is:
    </p>

    <pre><code># Option A: Increase prizes (keep more retrieved nodes)
prizes[relevant_nodes] = similarities[relevant_nodes] * 100

# Option B: Reduce edge costs (favor larger connected subgraphs)
costs = np.full(edges.shape[0], 0.01)

# Option C: Disable PCST entirely (pure Top-K retrieval)
subgraph_nodes = relevant_nodes</code></pre>

    <div class="success-box">
        <strong>Summary:</strong><br>
        PCST is a <em>filtering</em> mechanism that extracts the most
        structurally coherent core ‚Äî not an expansion step.
        Differences between retrieval output and final context are
        expected and indicate correct behavior.
    </div>
</div>

            </section>

            <section id="performance">
                <h2>üìà Performance Optimization</h2>

                <h3>For large vaults (>5000 notes):</h3>

                <div class="info-box">
                    <h4>1. Node Embedding Caching</h4>
                    <p>Pre-compute and store embeddings separately:</p>
                    <pre><code>import pickle
After first run
with open('node_embeddings.pkl', 'wb') as f:
    pickle.dump(self.node_embeddings, f)
In subsequent runs load
with open('node_embeddings.pkl', 'rb') as f:
    self.node_embeddings = pickle.load(f)</code></pre>
                </div>
                <div class="info-box">
                    <h4>2. Batch Processing for QA Generation</h4>
                    <p>Use larger batches:</p>
                    <pre><code># In generate_training_data.py
batch_size = 10  # Multiple prompts in parallel</code></pre>
                </div>
                <div class="info-box">
                    <h4>3. Graph Pruning</h4>
                    <p>Remove isolated nodes:</p>
                    <pre><code># After graph.build()
isolated = list(nx.isolates(self.graph))
self.graph.remove_nodes_from(isolated)</code></pre>
                </div>
                <h3>Benchmark (1100 nodes):</h3>

                <table>
                    <thead>
                        <tr>
                            <th>Operation</th>
                            <th>CPU (M1)</th>
                            <th>GPU (RTX 3080)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Graph Building</td>
                            <td>2 min</td>
                            <td>2 min</td>
                        </tr>
                        <tr>
                            <td>Node Embeddings</td>
                            <td>3 min</td>
                            <td>45 sec</td>
                        </tr>
                        <tr>
                            <td>500 QA pairs</td>
                            <td>90 min</td>
                            <td>90 min</td>
                        </tr>
                        <tr>
                            <td>PyG Dataset</td>
                            <td>8 min</td>
                            <td>3 min</td>
                        </tr>
                        <tr>
                            <td>Training (20 epochs)</td>
                            <td>180 min</td>
                            <td>45 min</td>
                        </tr>
                        <tr>
                            <td>Query Inference</td>
                            <td>3 sec</td>
                            <td>2 sec</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <section id="faq">
                <h2>‚ùì FAQ</h2>

                <div class="module-card">
                    <h4>Can I use other LLMs instead of Ollama?</h4>
                    <p>Yes! You can modify <code>generate_answer()</code> to use OpenAI, Anthropic, or other APIs. Ollama is just the privacy-friendly default option.</p>
                </div>

                <div class="module-card">
                    <h4>Does it also work with other note-taking apps?</h4>
                    <p>In principle, yes! You just need to adapt <code>obsidian_to_graph.py</code> to parse the specific format (e.g., Notion, Roam Research).</p>
                </div>

                <div class="module-card">
                    <h4>How do I keep the system up to date when I add new notes?</h4>
                    <p>Simply run the pipeline again. For incremental updates, you could write a script that processes only new/changed notes.</p>
                </div>

                <div class="module-card">
                    <h4>Can I use multiple vaults at the same time?</h4>
                    <p>Yes! Create a separate output folder for each vault. You can even combine multiple graphs in the same chat interface.</p>
                </div>

                <div class="module-card">
                    <h4>Are my data uploaded anywhere?</h4>
                    <p>No! Everything runs locally. Ollama is local, embeddings are local, training is local. Complete privacy.</p>
                </div>

                <div class="module-card">
                    <h4>Does the system work in other languages?</h4>
                    <p>Yes! Use multilingual embedding models and ensure your Ollama model supports the language. Llama3 works well with German, French, Spanish, etc.</p>
                </div>
            </section>

            <section id="resources">
                <h2>üìö Resources & Links</h2>

                <div class="module-card">
                    <h4>Papers & Research</h4>
                    <ul>
                        <li><a href="https://arxiv.org/abs/2402.07630" target="_blank">G-Retriever Paper (arXiv)</a></li>
                        <li><a href="https://pytorch-geometric.readthedocs.io/" target="_blank">PyTorch Geometric Documentation</a></li>
                        <li><a href="https://www.sbert.net/" target="_blank">Sentence Transformers</a></li>
                    </ul>
                </div>

                <div class="module-card">
                    <h4>Tools</h4>
                    <ul>
                        <li><a href="https://ollama.ai/" target="_blank">Ollama - Local LLMs</a></li>
                        <li><a href="https://obsidian.md/" target="_blank">Obsidian Note-Taking</a></li>
                        <li><a href="https://networkx.org/" target="_blank">NetworkX</a></li>
                    </ul>
                </div>

                <div class="module-card">
                    <h4>Community</h4>
                    <ul>
                        <li>PyTorch Geometric Discord</li>
                        <li>Obsidian Community Forum</li>
                        <li>r/LocalLLaMA on Reddit</li>
                    </ul>
                </div>
            </section>

            <section id="conclusion">
                <h2>üéâ Conclusion</h2>

                <div class="success-box">
                    <h3>You now have a complete graph-based RAG system!</h3>
                    <p>This system combines state-of-the-art technologies:</p>
                    <ul>
                        <li>‚úÖ Graph Neural Networks for structured knowledge</li>
                        <li>‚úÖ Semantic Search with embeddings</li>
                        <li>‚úÖ Intelligent subgraph construction (PCST)</li>
                        <li>‚úÖ Local LLMs for privacy</li>
                        <li>‚úÖ Modular, extensible code</li>
                    </ul>

                    <p style="margin-top: 20px;"><strong>Next Steps:</strong></p>
                    <ol>
                        <li>Start with the untrained variant</li>
                        <li>Test different questions</li>
                        <li>Generate more QA pairs if needed</li>
                        <li>Optional: Train for better results</li>
                        <li>Experiment with different models and parameters</li>
                    </ol>
                </div>

                <div style="text-align: center; margin: 40px 0;">
                    <a href="#overview" class="btn">Back to top</a>
                </div>
            </section>
        </main>

        <footer>
            <p><strong>G-Retriever for Obsidian</strong></p>
            <p>A modular system for intelligent knowledge graphs</p>
            <p style="margin-top: 20px; opacity: 0.8;">Created with PyTorch Geometric, Sentence Transformers & Ollama</p>
            <p style="margin-top: 10px; opacity: 0.6;">¬© 2024 - Open Source & Privacy First</p>
        </footer>
    </div>
</body>
</html>
